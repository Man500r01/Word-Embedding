{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYsk3BTaINYM",
        "outputId": "39cc9fdb-02d5-4280-f5a0-8531ad97531f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 497 entries, 0 to 496\n",
            "Data columns (total 2 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   Unnamed: 0  497 non-null    int64 \n",
            " 1   text        497 non-null    object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 7.9+ KB\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(style='seaborn')\n",
        "%matplotlib inline\n",
        "\n",
        "# read csv into a dataframe\n",
        "df_idf=pd.read_csv(\"output.csv\")\n",
        "\n",
        "df_idf.head()\n",
        "df_idf.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcFSM0QWINYO",
        "outputId": "f71abbb1-917a-4f0c-ce8e-192e3370da3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'youll love kindle ive mine months never looked back the new big one huge no need remorse'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 138
        }
      ],
      "source": [
        "import re\n",
        "def pre_process(text):\n",
        "    \n",
        "    # lowercase\n",
        "    text=text.lower()\n",
        "    \n",
        "    #remove tags\n",
        "    text=re.sub(\"</?.*?>\",\" <> \",text)\n",
        "    \n",
        "    # remove special characters and digits\n",
        "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
        "    \n",
        "    return text\n",
        "\n",
        "df_idf['text'] = df_idf['text'].apply(lambda x:pre_process(x))\n",
        "\n",
        "#show the first 'text'\n",
        "df_idf['text'][2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMCLElAOINYP"
      },
      "source": [
        "## Creating the IDF\n",
        "\n",
        "### CountVectorizer to create a vocabulary and generate word counts\n",
        "The next step is to start the counting process. We can use the CountVectorizer to create a vocabulary from all the text in our `df_idf['text']` and generate counts for each row in `df_idf['text']`. The result of the last two lines is a sparse matrix representation of the counts, meaning each column represents a word in the vocabulary and each row represents the document in our dataset where the values are the word counts. Note that with this representation, counts of some words could be 0 if the word did not appear in the corresponding document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyXmBjlqINYQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import re\n",
        "\n",
        "def get_stop_words(stop_file_path):\n",
        "    \"\"\"load stop words \"\"\"\n",
        "    \n",
        "    with open(stop_file_path, 'r', encoding=\"utf-8\") as f:\n",
        "        stopwords = f.readlines()\n",
        "        stop_set = set(m.strip() for m in stopwords)\n",
        "        return frozenset(stop_set)\n",
        "\n",
        "#load a set of stop words\n",
        "stopwords=get_stop_words(\"stopwords.txt\")\n",
        "\n",
        "#get the text column \n",
        "docs=df_idf['text'].tolist()\n",
        "\n",
        "#create a vocabulary of words, \n",
        "#ignore words that appear in 85% of documents, \n",
        "#eliminate stop words\n",
        "cv=CountVectorizer(max_df=0.85,stop_words=stopwords)\n",
        "word_count_vector=cv.fit_transform(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoB1MY22INYR"
      },
      "source": [
        "Now let's check the shape of the resulting vector. Notice that the shape below is `(20000,124901)` because we have 20,000 documents in our dataset (the rows) and the vocabulary size is `124901` meaning we have `124901` unique words (the columns) in our dataset minus the stopwords."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GNLccG0INYR",
        "outputId": "a6e89053-edc7-4488-cd37-be45efa67fdf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(497, 1951)"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ],
      "source": [
        "word_count_vector.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLbEMB7xINYS"
      },
      "source": [
        "Let's limit our vocabulary size to 10,000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X958XGBuINYS",
        "outputId": "147de9d2-b4ee-46dc-d3ae-6e47ecd87489",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(497, 1951)"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ],
      "source": [
        "cv=CountVectorizer(max_df=0.85,stop_words=stopwords,max_features=124901)\n",
        "word_count_vector=cv.fit_transform(docs)\n",
        "word_count_vector.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNn8QGZ0INYS"
      },
      "source": [
        "Now, let's look at 10 words from our vocabulary. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqgoSEb_INYT",
        "outputId": "20dc6ef2-8595-490c-aa38-77f1095e570c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['reading',\n",
              " 'kindle',\n",
              " 'love',\n",
              " 'lee',\n",
              " 'childs',\n",
              " 'good',\n",
              " 'read',\n",
              " 'ok',\n",
              " 'first',\n",
              " 'assesment']"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ],
      "source": [
        "list(cv.vocabulary_.keys())[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bl6vCF9wINYT"
      },
      "source": [
        "We can also get the vocabulary by using `get_feature_names()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ykc4TG3mINYT",
        "outputId": "ca32037f-c413-4af3-b5d8-72c388a0bc4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ],
      "source": [
        "list(cv.get_feature_names())[2000:2015]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Li6Z3Oh2INYU"
      },
      "source": [
        "### TfidfTransformer to Compute Inverse Document Frequency (IDF) \n",
        "In the code below, we are essentially taking the sparse matrix from CountVectorizer to generate the IDF when you invoke `fit`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIrCBvEiINYU",
        "outputId": "9877a747-6b92-471a-8000-3d868580dabd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfTransformer()"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
        "tfidf_transformer.fit(word_count_vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axSGDveqINYU"
      },
      "source": [
        "Let's look at some of the IDF values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y19fbnKvINYU",
        "outputId": "21c461a4-f404-45fa-e118-fbd2661f4a0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6.5174529 , 6.5174529 , 6.11198779, ..., 6.5174529 , 6.5174529 ,\n",
              "       6.5174529 ])"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ],
      "source": [
        "tfidf_transformer.idf_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlfmXI5uINYV"
      },
      "source": [
        "## Computing TF-IDF and Extracting Keywords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAcfte7iINYV"
      },
      "source": [
        "Once we have our IDF computed, we are now ready to compute TF-IDF and extract the top keywords."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdsrXXSLINYV"
      },
      "outputs": [],
      "source": [
        "# read test docs into a dataframe and concatenate title and body\n",
        "df_test=pd.read_csv(\"output.csv\")\n",
        "df_test['text'] =df_test['text'].apply(lambda x:pre_process(x))\n",
        "\n",
        "# get test docs into a list\n",
        "docs_test=df_test['text'].tolist()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTJhrfZYINYV"
      },
      "outputs": [],
      "source": [
        "def sort_coo(coo_matrix):\n",
        "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
        "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
        "\n",
        "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
        "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
        "    \n",
        "    #use only topn items from vector\n",
        "    sorted_items = sorted_items[:topn]\n",
        "\n",
        "    score_vals = []\n",
        "    feature_vals = []\n",
        "\n",
        "    for idx, score in sorted_items:\n",
        "        fname = feature_names[idx]\n",
        "        \n",
        "        #keep track of feature name and its corresponding score\n",
        "        score_vals.append(round(score, 3))\n",
        "        feature_vals.append(feature_names[idx])\n",
        "\n",
        "    #create a tuples of feature,score\n",
        "    #results = zip(feature_vals,score_vals)\n",
        "    results= {}\n",
        "    for idx in range(len(feature_vals)):\n",
        "        results[feature_vals[idx]]=score_vals[idx]\n",
        "    \n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQ_Mk43RINYW"
      },
      "source": [
        "The next step is to compute the tf-idf value for a given document in our test set by invoking `tfidf_transformer.transform(...)`. This generates a vector of tf-idf scores. Next, we sort the words in the vector in descending order of tf-idf values and then iterate over to extract the top-n items with the corresponding feature names, In the example below, we are extracting keywords for the first document in our test set. \n",
        "\n",
        "The `sort_coo(...)` method essentially sorts the values in the vector while preserving the column index. Once you have the column index then its really easy to look-up the corresponding word value as you would see in `extract_topn_from_vector(...)` where we do `feature_vals.append(feature_names[idx])`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFWrYBAqINYW",
        "outputId": "0e51c301-5410-4363-e717-fdc9219d38bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=====Title=====\n",
            "reading kindle love lee childs good read\n",
            "\n",
            "===Keywords===\n",
            "lee 0.478\n",
            "childs 0.478\n",
            "read 0.386\n",
            "reading 0.376\n",
            "kindle 0.309\n",
            "love 0.29\n",
            "good 0.272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "# you only needs to do this once\n",
        "feature_names=cv.get_feature_names()\n",
        "\n",
        "# get the document that we want to extract keywords from\n",
        "doc=docs_test[0]\n",
        "\n",
        "#generate tf-idf for the given document\n",
        "tf_idf_vector=tfidf_transformer.transform(cv.transform([doc]))\n",
        "\n",
        "#sort the tf-idf vectors by descending order of scores\n",
        "sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
        "\n",
        "#extract only the top n; n here is 10\n",
        "keywords=extract_topn_from_vector(feature_names,sorted_items,10)\n",
        "\n",
        "# now print the results\n",
        "print(\"\\n=====Title=====\")\n",
        "\n",
        "print(docs_test[0])\n",
        "print(\"\\n===Keywords===\")\n",
        "for k in keywords:\n",
        "    print(k,keywords[k])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOi22HqcINYW"
      },
      "outputs": [],
      "source": [
        "# put the common code into several methods\n",
        "def get_keywords(idx):\n",
        "\n",
        "    #generate tf-idf for the given document\n",
        "    tf_idf_vector=tfidf_transformer.transform(cv.transform([docs_test[idx]]))\n",
        "\n",
        "    #sort the tf-idf vectors by descending order of scores\n",
        "    sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
        "\n",
        "    #extract only the top n; n here is 10\n",
        "    keywords=extract_topn_from_vector(feature_names,sorted_items,10)\n",
        "    \n",
        "    return keywords\n",
        "\n",
        "def print_results(idx,keywords):\n",
        "    # now print the results\n",
        " \n",
        "    print(\"\\n===Keywords===\")\n",
        "    for k in keywords:\n",
        "        print(k,keywords[k])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dX8qJFRbINYX"
      },
      "source": [
        "Now let's look at keywords generated for a much longer question: \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FbTJOn0INYX",
        "outputId": "b1290519-ea9a-467c-b0de-55f0d951da21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===Keywords===\n",
            "marketing 0.47\n",
            "sitcom 0.291\n",
            "nbccom 0.291\n",
            "market 0.291\n",
            "judd 0.291\n",
            "fake 0.291\n",
            "creates 0.291\n",
            "apatow 0.291\n",
            "viral 0.242\n",
            "movie 0.242\n"
          ]
        }
      ],
      "source": [
        "idx=120\n",
        "keywords=get_keywords(idx)\n",
        "print_results(idx,keywords)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuOI9WZxINYX"
      },
      "source": [
        "## Generate keywords for a batch of documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-QmPBVmINYX",
        "outputId": "ae07680b-0a96-4712-f22f-3cf179a43d7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   doc  \\\n",
              "0             reading kindle love lee childs good read   \n",
              "1              ok first assesment kindle fucking rocks   \n",
              "2    youll love kindle ive mine months never looked...   \n",
              "3               fair enough but kindle i think perfect   \n",
              "4                           big im quite happy kindle    \n",
              "..                                                 ...   \n",
              "492  ask programming latex indesign submitted calci...   \n",
              "493  on note i hate word i hate pages i hate latex ...   \n",
              "494  ahhh back real text editing environment i lt l...   \n",
              "495  trouble iran i see hmm iran iran far away floc...   \n",
              "496  reading tweets coming iran the whole thing ter...   \n",
              "\n",
              "                                              keywords  \n",
              "0    {'lee': 0.478, 'childs': 0.478, 'read': 0.386,...  \n",
              "1    {'assesment': 0.468, 'rocks': 0.439, 'first': ...  \n",
              "2    {'youll': 0.295, 'remorse': 0.295, 'months': 0...  \n",
              "3    {'fair': 0.457, 'perfect': 0.428, 'enough': 0....  \n",
              "4    {'quite': 0.524, 'big': 0.488, 'happy': 0.462,...  \n",
              "..                                                 ...  \n",
              "492  {'submitted': 0.366, 'programming': 0.366, 'in...  \n",
              "493  {'hate': 0.616, 'latex': 0.345, 'texn': 0.229,...  \n",
              "494  {'environment': 0.392, 'editing': 0.392, 'ahhh...  \n",
              "495  {'iran': 0.747, 'trouble': 0.29, 'hmm': 0.29, ...  \n",
              "496  {'terrifying': 0.361, 'incredibly': 0.361, 'co...  \n",
              "\n",
              "[497 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e35c6d88-944d-4565-97ce-785f4b7a828f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc</th>\n",
              "      <th>keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>reading kindle love lee childs good read</td>\n",
              "      <td>{'lee': 0.478, 'childs': 0.478, 'read': 0.386,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ok first assesment kindle fucking rocks</td>\n",
              "      <td>{'assesment': 0.468, 'rocks': 0.439, 'first': ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>youll love kindle ive mine months never looked...</td>\n",
              "      <td>{'youll': 0.295, 'remorse': 0.295, 'months': 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>fair enough but kindle i think perfect</td>\n",
              "      <td>{'fair': 0.457, 'perfect': 0.428, 'enough': 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>big im quite happy kindle</td>\n",
              "      <td>{'quite': 0.524, 'big': 0.488, 'happy': 0.462,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>492</th>\n",
              "      <td>ask programming latex indesign submitted calci...</td>\n",
              "      <td>{'submitted': 0.366, 'programming': 0.366, 'in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>493</th>\n",
              "      <td>on note i hate word i hate pages i hate latex ...</td>\n",
              "      <td>{'hate': 0.616, 'latex': 0.345, 'texn': 0.229,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>ahhh back real text editing environment i lt l...</td>\n",
              "      <td>{'environment': 0.392, 'editing': 0.392, 'ahhh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>trouble iran i see hmm iran iran far away floc...</td>\n",
              "      <td>{'iran': 0.747, 'trouble': 0.29, 'hmm': 0.29, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>reading tweets coming iran the whole thing ter...</td>\n",
              "      <td>{'terrifying': 0.361, 'incredibly': 0.361, 'co...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>497 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e35c6d88-944d-4565-97ce-785f4b7a828f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e35c6d88-944d-4565-97ce-785f4b7a828f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e35c6d88-944d-4565-97ce-785f4b7a828f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ],
      "source": [
        "#generate tf-idf for all documents in your list. docs_test has 500 documents\n",
        "tf_idf_vector=tfidf_transformer.transform(cv.transform(docs_test))\n",
        "\n",
        "results=[]\n",
        "for i in range(tf_idf_vector.shape[0]):\n",
        "    \n",
        "    # get vector for a single document\n",
        "    curr_vector=tf_idf_vector[i]\n",
        "    \n",
        "    #sort the tf-idf vector by descending order of scores\n",
        "    sorted_items=sort_coo(curr_vector.tocoo())\n",
        "\n",
        "    #extract only the top n; n here is 10\n",
        "    keywords=extract_topn_from_vector(feature_names,sorted_items,10)\n",
        "    \n",
        "    \n",
        "    results.append(keywords)\n",
        "\n",
        "df=pd.DataFrame(zip(docs,results),columns=['doc','keywords'])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**n-gram Implementation**"
      ],
      "metadata": {
        "id": "_Wzp7BGgajOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save = pd.DataFrame(df).to_csv(\"result.csv\")"
      ],
      "metadata": {
        "id": "eJiCjSb3XXiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save1= pd.read_csv('result.csv')\n",
        "print(save1.head())"
      ],
      "metadata": {
        "id": "bhJCyNurXs68",
        "outputId": "b6983036-a849-4036-e9da-070d038a6142",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0                                                doc  \\\n",
            "0           0           reading kindle love lee childs good read   \n",
            "1           1            ok first assesment kindle fucking rocks   \n",
            "2           2  youll love kindle ive mine months never looked...   \n",
            "3           3             fair enough but kindle i think perfect   \n",
            "4           4                         big im quite happy kindle    \n",
            "\n",
            "                                            keywords  \n",
            "0  {'lee': 0.478, 'childs': 0.478, 'read': 0.386,...  \n",
            "1  {'assesment': 0.468, 'rocks': 0.439, 'first': ...  \n",
            "2  {'youll': 0.295, 'remorse': 0.295, 'months': 0...  \n",
            "3  {'fair': 0.457, 'perfect': 0.428, 'enough': 0....  \n",
            "4  {'quite': 0.524, 'big': 0.488, 'happy': 0.462,...  \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Raw Cell Format",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Assignment for Word to vector conversion with TF-IDF.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}